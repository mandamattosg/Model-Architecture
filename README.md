# Arquitetura de Produ√ß√£o Escal√°vel para um Modelo de Machine Learning

Aqui foi descrito cada etapa de uma arquitetura pensada para operacionalizar um modelo de Machine Learning em um ambiente empresarial com alta escala.
## üóÇÔ∏è Diagrama da Arquitetura
<div align="center">
  <img width="735" height="489" alt="Captura de tela 2025-08-02 120515" src="https://github.com/user-attachments/assets/6422c100-29ed-45bf-97c2-f64d121fb753" />
</div>
## üìÑ Explica√ß√£o da Arquitetura

#### 1. Componentes do Sistema

1. Fontes de Dados: Representam as diversas origens de onde os dados brutos (imagens e v√≠deos) s√£o coletados. Podem ser c√¢meras de vigil√¢ncia, APIs de terceiros ou uploads de usu√°rios.

2. Servi√ßo de Ingest√£o: Uma camada de API ou um microsservi√ßo que recebe os dados brutos das fontes, valida, padroniza e inicia o fluxo de processamento. Faz o upload dos arquivos brutos para o Armazenamento para que sejam guardados de forma dur√°vel e envia os metadados desses arquivos (como o caminho e a data/hora) para a Fila de Mensagens.

3. Fila de Mensagens: Desacopla a ingest√£o do processamento. Recebe os metadados de novos dados em tempo real e os armazena de forma dur√°vel. O servi√ßo de Pr√©-processamento atua como consumidor que puxa as mensagens da fila.

4. Pr√©-processamento: Um servi√ßo dedicado que consome as mensagens da fila e √© respons√°vel por preparar os dados para o treinamento do modelo. L√™ os arquivos brutos do Armazenamento, processa as imagens e v√≠deos (redimensiona, extrai frames, aplica filtros, etc) e armazena os dados processados. Tamb√©m registra na Base de Dados os metadados do processamento como o status, o caminho final e os par√¢metros utilizados. Isso √© importante para a rastreabilidade do pipeline.

5. Armazenamento: O reposit√≥rio central para todos os dados do sistema. Dividido em √°reas para armazenar dados brutos e dados j√° processados, garantindo organiza√ß√£o e efici√™ncia.

6. Pipeline de Treinamento: Um fluxo de trabalho automatizado que orquestra o ciclo de vida de treinamento do modelo. L√™ os dados processados, obt√©m os r√≥tulos da Base de Dados e, ap√≥s o treinamento e a avalia√ß√£o, registra o modelo treinado no Registro de Modelo.

7. Registro de Modelo: Um reposit√≥rio central que armazena, versiona e gerencia os modelos de machine learning. Cada modelo treinado tem uma vers√£o e metadados associados, como m√©tricas de performance e os hiperpar√¢metros utilizados, o que √© fundamental para gerenciamento e reprodutibilidade.

8.  Servi√ßo de Infer√™ncia: Um cluster de cont√™ineres que hospeda a API de infer√™ncia em alta escala. √â o componente que consome o modelo treinado e o disponibiliza para requisi√ß√µes externas.

9. Monitoramento: Um sistema para coletar e visualizar m√©tricas de performance do sistema em tempo real. Um monitora as m√©tricas de performance do modelo (acur√°cia, precis√£o), decidindo se √© necess√°rio retreinar o modelo e outro analisa as m√©tricas de sistema vindas do Servi√ßo de Infer√™ncia (CPU, lat√™ncia). 

10. Base de Dados: Armazena metadados estruturados, como r√≥tulos das imagens, logs de treinamento e dados de monitoramento. Atua como fonte para os r√≥tulos de treinamento e para o feedback do modelo.

#### 2. Justificativas das Escolhas Tecnol√≥gicas

* Apache Kafka para Fila de Mensagens: Escolhido por sua alta escalabilidade e resili√™ncia. √â uma boa solu√ß√£o para gerenciar o fluxo de dados de m√∫ltiplas fontes em tempo real garantindo que nenhum dado seja perdido e desacoplando os servi√ßos.
* Amazon S3 para Armazenamento: √â o padr√£o da ind√∫stria para armazenamento de objetos e oferece durabilidade, escalabilidade e baixo custo. √â importante para armazenar grandes volumes de imagens e v√≠deos de alta resolu√ß√£o, al√©m de suportar versionamento de dados.
* Kubeflow/AWS SageMaker para Pipeline de Treinamento: Estas plataformas fornecem acesso gerenciado a GPUs, orquestram o fluxo de trabalho de treinamento e garantem a reprodutibilidade e a automa√ß√£o do processo.
* MLflow para Registro do Modelo: √â uma ferramenta de c√≥digo aberto essencial para o gerenciamento do ciclo de vida do modelo. Sua principal vantagem √© o versionamento de modelos, que permite rastrear e registrar modelos de forma organizada.
* Kubernetes e FastAPI para Servi√ßo de Infer√™ncia: O Kubernetes gerencia a cria√ß√£o de m√∫ltiplos cont√™ineres com a API do FastAPI e os escala automaticamente para lidar com milhares de requisi√ß√µes por segundo, enquanto um API Gateway protege o endpoint.
* PostgreSQL para Base de Dados: Escolhido por sua confiabilidade, integridade de dados e capacidade de armazenamento estruturado, sendo ideal para catalogar metadados gerados em diversas etapas do pipeline.
* Prometheus e Grafana para Monitoramento: S√£o as ferramentas mais utilizadas para monitoramento em tempo real. O Prometheus coleta m√©tricas do sistema e do modelo, e o Grafana as visualiza em dashboards customiz√°veis, permitindo o acompanhamento do sistema e da performance do modelo em produ√ß√£o.
